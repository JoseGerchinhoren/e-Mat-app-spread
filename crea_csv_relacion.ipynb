{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proceso completado. Se guardaron 235642 filas en 'historico_comparacion.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "# Nombre del archivo CSV local\n",
    "csv_file_name = 'historico_ajustes_para_relacion.csv'\n",
    "\n",
    "# Función principal\n",
    "def procesar_spread_localmente():\n",
    "    try:\n",
    "        # Leer el archivo CSV existente localmente\n",
    "        try:\n",
    "            combined_data = pd.read_csv(csv_file_name)\n",
    "            if 'FECHA' not in combined_data.columns:\n",
    "                raise ValueError(\"La columna 'FECHA' no está presente en el archivo CSV.\")\n",
    "        except FileNotFoundError:\n",
    "            combined_data = pd.DataFrame(columns=[\"PRODUCTO\", \"TIPO CONTRATO\", \"AJUSTE / PRIMA REF.\", \"AÑO\", \"MES-DIA\", \"FECHA\"])\n",
    "            return \"No se encontró el archivo CSV local. Se ha creado un DataFrame vacío.\"\n",
    "\n",
    "        # Asegurarse de que la columna 'FECHA' esté en formato datetime\n",
    "        combined_data['FECHA'] = pd.to_datetime(combined_data['FECHA'], format='%Y-%m-%d', errors='coerce')\n",
    "        \n",
    "        # Generar una lista de tuplas que contenga todas las combinaciones de productos y posiciones\n",
    "        productos_posiciones = combined_data[['PRODUCTO', 'TIPO CONTRATO']].drop_duplicates().values.tolist()\n",
    "\n",
    "        # Generar todas las combinaciones de productos y posiciones, incluyendo comparaciones invertidas\n",
    "        combinaciones = [(p1, t1, p2, t2) for (p1, t1), (p2, t2) in itertools.product(productos_posiciones, repeat=2)\n",
    "                         if not (p1 == p2 and t1 == t2)]  # Excluir comparaciones con el mismo producto y posición\n",
    "\n",
    "        resultados = []\n",
    "        for p1, t1, p2, t2 in combinaciones:\n",
    "            df_pos1 = combined_data[(combined_data['PRODUCTO'] == p1) & (combined_data['TIPO CONTRATO'] == t1)]\n",
    "            df_pos2 = combined_data[(combined_data['PRODUCTO'] == p2) & (combined_data['TIPO CONTRATO'] == t2)]\n",
    "\n",
    "            # Utilizar la columna 'FECHA' para hacer la combinación\n",
    "            merged = pd.merge(df_pos1, df_pos2, on='FECHA', suffixes=('_pos1', '_pos2'))\n",
    "            \n",
    "            merged['SPREAD'] = (merged['AJUSTE / PRIMA REF._pos1'] - merged['AJUSTE / PRIMA REF._pos2']).round(3)\n",
    "            merged['RELACION%'] = ((merged['AJUSTE / PRIMA REF._pos1'] / merged['AJUSTE / PRIMA REF._pos2'] - 1) * 100).round(3)\n",
    "\n",
    "            for index, row in merged.iterrows():\n",
    "                resultados.append({\n",
    "                    'FECHA': row['FECHA'].strftime('%Y-%m-%d'),  # Usamos la fecha generada\n",
    "                    'PRODUCTO_1': p1,\n",
    "                    'TIPO_CONTRATO_1': t1,\n",
    "                    'PRODUCTO_2': p2,\n",
    "                    'TIPO_CONTRATO_2': t2,\n",
    "                    'AJUSTE_POS1': row['AJUSTE / PRIMA REF._pos1'],\n",
    "                    'AJUSTE_POS2': row['AJUSTE / PRIMA REF._pos2'],\n",
    "                    'SPREAD': row['SPREAD'],\n",
    "                    'RELACION%': row['RELACION%']\n",
    "                })\n",
    "\n",
    "        # Guardar los resultados en un nuevo archivo CSV local\n",
    "        resultados_df = pd.DataFrame(resultados)\n",
    "        resultados_df.to_csv('historico_relacion.csv', index=False)\n",
    "\n",
    "        # Contar cuántas filas se guardaron en spread_comparison.csv\n",
    "        filas_spread_comparison = len(resultados_df)\n",
    "\n",
    "        return f\"Proceso completado. Se guardaron {filas_spread_comparison} filas en 'historico_relacion.csv'.\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error durante el procesamiento: {str(e)}\"\n",
    "\n",
    "# Ejecutar la función\n",
    "resultado = procesar_spread_localmente()\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proceso completado. Se guardaron 240 filas en 'historico_comparacion.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "import requests\n",
    "import csv\n",
    "import re\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "# Nombre del archivo CSV local\n",
    "csv_file_name = 'historico_ajustes_para_relacion.csv'\n",
    "\n",
    "def obtener_productos_agricolas():\n",
    "    try:\n",
    "        # Leer el archivo CSV existente localmente\n",
    "        with open(csv_file_name, mode='r', encoding='utf-8') as file:\n",
    "            csv_reader = csv.DictReader(file)\n",
    "            productos_agricolas = set(row['PRODUCTO'] for row in csv_reader)\n",
    "        return productos_agricolas\n",
    "    except FileNotFoundError:\n",
    "        return set()\n",
    "\n",
    "def es_opcion(tipo_contrato):\n",
    "    # Patrón que detecta si el contrato contiene un número seguido de una letra (p.ej. \"185 C\")\n",
    "    patron_opcion = re.compile(r'\\d+ [A-Z]')\n",
    "    return bool(patron_opcion.search(tipo_contrato))\n",
    "\n",
    "def procesar_spread_localmente():\n",
    "    try:\n",
    "        # Calcular la fecha de hoy\n",
    "        today = datetime.now()\n",
    "        today_str = today.strftime('%Y-%m-%d')\n",
    "\n",
    "        # Definir la URL del endpoint de precios de cierre\n",
    "        url_closing_prices = 'https://apicem.matbarofex.com.ar/api/v2/closing-prices'\n",
    "        params = {\n",
    "            \"from\": today_str, #\"2024-08-06\",\n",
    "            \"to\": today_str, #\"2024-08-06\",\n",
    "            \"market\": \"ROFX\",\n",
    "            \"version\": \"v2\"\n",
    "        }\n",
    "\n",
    "        # Obtener la lista de productos agrícolas\n",
    "        productos_agricolas = obtener_productos_agricolas()\n",
    "\n",
    "        # Realizar la solicitud a la API para obtener la lista de precios de cierre\n",
    "        response_closing_prices = requests.get(url_closing_prices, params=params)\n",
    "        \n",
    "        if response_closing_prices.status_code != 200:\n",
    "            return f\"Error en la solicitud a la API: {response_closing_prices.status_code}\"\n",
    "\n",
    "        try:\n",
    "            data_closing_prices = response_closing_prices.json()\n",
    "\n",
    "            # Filtrar las columnas deseadas y cambiar el formato de los nombres de las columnas\n",
    "            filtered_data = [\n",
    "                {\n",
    "                    \"FECHA\": item.get(\"dateTime\")[:10],  # Extraer solo la fecha\n",
    "                    \"PRODUCTO\": item.get(\"product\"),\n",
    "                    \"TIPO CONTRATO\": item.get(\"symbol\"),\n",
    "                    \"AJUSTE / PRIMA REF.\": item.get(\"settlement\")\n",
    "                }\n",
    "                for item in data_closing_prices.get('data', [])\n",
    "                if item.get(\"product\") in productos_agricolas and not es_opcion(item.get(\"symbol\"))\n",
    "            ]\n",
    "\n",
    "            # # Cargar los datos existentes si el archivo CSV existe\n",
    "            # try:\n",
    "            #     existing_data = pd.read_csv(csv_file_name)\n",
    "            # except FileNotFoundError:\n",
    "            #     existing_data = pd.DataFrame(columns=[\"FECHA\", \"PRODUCTO\", \"TIPO CONTRATO\", \"AJUSTE / PRIMA REF.\"])\n",
    "\n",
    "            # # Combinar los datos existentes con los nuevos datos\n",
    "            new_data = pd.DataFrame(filtered_data)\n",
    "\n",
    "            # Asegurarse de que la columna 'FECHA' esté en formato datetime\n",
    "            new_data['FECHA'] = pd.to_datetime(new_data['FECHA'], format='%Y-%m-%d', errors='coerce')\n",
    "\n",
    "            # combined_data = pd.concat([existing_data, new_data]).drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "            # # Asegurarse de que la columna 'FECHA' esté en formato datetime\n",
    "            # combined_data['FECHA'] = pd.to_datetime(combined_data['FECHA'], format='%Y-%m-%d', errors='coerce')\n",
    "\n",
    "            # # Guardar los datos combinados en el archivo CSV\n",
    "            # combined_data.to_csv(csv_file_name, index=False)\n",
    "\n",
    "            # Generar una lista de tuplas que contenga todas las combinaciones de productos y posiciones\n",
    "            productos_posiciones = new_data[['PRODUCTO', 'TIPO CONTRATO']].drop_duplicates().values.tolist()\n",
    "\n",
    "            # Generar todas las combinaciones de productos y posiciones, incluyendo comparaciones invertidas\n",
    "            combinaciones = [(p1, t1, p2, t2) for (p1, t1), (p2, t2) in itertools.product(productos_posiciones, repeat=2)\n",
    "                             if not (p1 == p2 and t1 == t2)]  # Excluir comparaciones con el mismo producto y posición\n",
    "\n",
    "            resultados = []\n",
    "            for p1, t1, p2, t2 in combinaciones:\n",
    "                df_pos1 = new_data[(new_data['PRODUCTO'] == p1) & (new_data['TIPO CONTRATO'] == t1)]\n",
    "                df_pos2 = new_data[(new_data['PRODUCTO'] == p2) & (new_data['TIPO CONTRATO'] == t2)]\n",
    "\n",
    "                # Utilizar la columna 'FECHA' para hacer la combinación\n",
    "                merged = pd.merge(df_pos1, df_pos2, on='FECHA', suffixes=('_pos1', '_pos2'))\n",
    "\n",
    "                merged['SPREAD'] = (merged['AJUSTE / PRIMA REF._pos1'] - merged['AJUSTE / PRIMA REF._pos2']).round(3)\n",
    "                merged['RELACION%'] = ((merged['AJUSTE / PRIMA REF._pos1'] / merged['AJUSTE / PRIMA REF._pos2'] - 1) * 100).round(3)\n",
    "\n",
    "                for index, row in merged.iterrows():\n",
    "                    resultados.append({\n",
    "                        'FECHA': row['FECHA'].strftime('%Y-%m-%d'),  # Usamos la fecha generada\n",
    "                        'PRODUCTO_1': p1,\n",
    "                        'TIPO_CONTRATO_1': t1,\n",
    "                        'PRODUCTO_2': p2,\n",
    "                        'TIPO_CONTRATO_2': t2,\n",
    "                        'AJUSTE_POS1': row['AJUSTE / PRIMA REF._pos1'],\n",
    "                        'AJUSTE_POS2': row['AJUSTE / PRIMA REF._pos2'],\n",
    "                        'SPREAD': row['SPREAD'],\n",
    "                        'RELACION%': row['RELACION%']\n",
    "                    })\n",
    "\n",
    "            # Guardar los resultados en un nuevo archivo CSV local\n",
    "            resultados_df = pd.DataFrame(resultados)\n",
    "            resultados_df.to_csv('relaciones_hoy.csv', index=False)\n",
    "\n",
    "            filas_spread_comparison = len(resultados_df)\n",
    "            return f\"Proceso completado. Se guardaron {filas_spread_comparison} filas en 'historico_relacion.csv'.\"\n",
    "\n",
    "        except json.JSONDecodeError:\n",
    "            return \"Error al decodificar la respuesta de la API.\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error durante el procesamiento: {str(e)}\"\n",
    "\n",
    "# Ejecutar la función\n",
    "resultado = procesar_spread_localmente()\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proceso completado. Se guardaron 240 filas en 'historico_comparacion.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "import requests\n",
    "import csv\n",
    "import re\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "# Nombre del archivo CSV local\n",
    "csv_file_name = 'historico_ajustes_para_relacion.csv'\n",
    "\n",
    "def obtener_productos_agricolas():\n",
    "    try:\n",
    "        # Leer el archivo CSV existente localmente\n",
    "        with open(csv_file_name, mode='r', encoding='utf-8') as file:\n",
    "            csv_reader = csv.DictReader(file)\n",
    "            productos_agricolas = set(row['PRODUCTO'] for row in csv_reader)\n",
    "        return productos_agricolas\n",
    "    except FileNotFoundError:\n",
    "        return set()\n",
    "\n",
    "def es_opcion(tipo_contrato):\n",
    "    # Patrón que detecta si el contrato contiene un número seguido de una letra (p.ej. \"185 C\")\n",
    "    patron_opcion = re.compile(r'\\d+ [A-Z]')\n",
    "    return bool(patron_opcion.search(tipo_contrato))\n",
    "\n",
    "def procesar_spread_localmente():\n",
    "    try:\n",
    "        # Calcular la fecha de hoy\n",
    "        today = datetime.now()\n",
    "        today_str = today.strftime('%Y-%m-%d')\n",
    "\n",
    "        # Definir la URL del endpoint de precios de cierre\n",
    "        url_closing_prices = 'https://apicem.matbarofex.com.ar/api/v2/closing-prices'\n",
    "        params = {\n",
    "            \"from\": \"2024-08-06\",\n",
    "            \"to\": \"2024-08-06\",\n",
    "            \"market\": \"ROFX\",\n",
    "            \"version\": \"v2\"\n",
    "        }\n",
    "\n",
    "        # Obtener la lista de productos agrícolas\n",
    "        productos_agricolas = obtener_productos_agricolas()\n",
    "\n",
    "        # Realizar la solicitud a la API para obtener la lista de precios de cierre\n",
    "        response_closing_prices = requests.get(url_closing_prices, params=params)\n",
    "        \n",
    "        if response_closing_prices.status_code != 200:\n",
    "            return f\"Error en la solicitud a la API: {response_closing_prices.status_code}\"\n",
    "\n",
    "        try:\n",
    "            data_closing_prices = response_closing_prices.json()\n",
    "\n",
    "            # Filtrar las columnas deseadas y cambiar el formato de los nombres de las columnas\n",
    "            filtered_data = [\n",
    "                {\n",
    "                    \"FECHA\": item.get(\"dateTime\")[:10],  # Extraer solo la fecha\n",
    "                    \"PRODUCTO\": item.get(\"product\"),\n",
    "                    \"TIPO CONTRATO\": item.get(\"symbol\"),\n",
    "                    \"AJUSTE / PRIMA REF.\": item.get(\"settlement\")\n",
    "                }\n",
    "                for item in data_closing_prices.get('data', [])\n",
    "                if item.get(\"product\") in productos_agricolas and not es_opcion(item.get(\"symbol\"))\n",
    "            ]\n",
    "\n",
    "            # Cargar los datos existentes si el archivo CSV existe\n",
    "            try:\n",
    "                existing_data = pd.read_csv(csv_file_name)\n",
    "            except FileNotFoundError:\n",
    "                existing_data = pd.DataFrame(columns=[\"FECHA\", \"PRODUCTO\", \"TIPO CONTRATO\", \"AJUSTE / PRIMA REF.\"])\n",
    "\n",
    "            # # Combinar los datos existentes con los nuevos datos\n",
    "            new_data = pd.DataFrame(filtered_data)\n",
    "\n",
    "            # Asegurarse de que la columna 'FECHA' esté en formato datetime\n",
    "            new_data['FECHA'] = pd.to_datetime(new_data['FECHA'], format='%Y-%m-%d', errors='coerce')\n",
    "\n",
    "            combined_data = pd.concat([existing_data, new_data]).drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "            # Asegurarse de que la columna 'FECHA' esté en formato datetime\n",
    "            combined_data['FECHA'] = pd.to_datetime(combined_data['FECHA'], format='%Y-%m-%d', errors='coerce')\n",
    "\n",
    "            # Guardar los datos combinados en el archivo CSV\n",
    "            combined_data.to_csv(csv_file_name, index=False)\n",
    "\n",
    "            # Generar una lista de tuplas que contenga todas las combinaciones de productos y posiciones\n",
    "            productos_posiciones = new_data[['PRODUCTO', 'TIPO CONTRATO']].drop_duplicates().values.tolist()\n",
    "\n",
    "            # Generar todas las combinaciones de productos y posiciones, incluyendo comparaciones invertidas\n",
    "            combinaciones = [(p1, t1, p2, t2) for (p1, t1), (p2, t2) in itertools.product(productos_posiciones, repeat=2)\n",
    "                             if not (p1 == p2 and t1 == t2)]  # Excluir comparaciones con el mismo producto y posición\n",
    "\n",
    "            resultados = []\n",
    "            for p1, t1, p2, t2 in combinaciones:\n",
    "                df_pos1 = new_data[(new_data['PRODUCTO'] == p1) & (new_data['TIPO CONTRATO'] == t1)]\n",
    "                df_pos2 = new_data[(new_data['PRODUCTO'] == p2) & (new_data['TIPO CONTRATO'] == t2)]\n",
    "\n",
    "                # Utilizar la columna 'FECHA' para hacer la combinación\n",
    "                merged = pd.merge(df_pos1, df_pos2, on='FECHA', suffixes=('_pos1', '_pos2'))\n",
    "\n",
    "                merged['SPREAD'] = (merged['AJUSTE / PRIMA REF._pos1'] - merged['AJUSTE / PRIMA REF._pos2']).round(3)\n",
    "                merged['RELACION%'] = ((merged['AJUSTE / PRIMA REF._pos1'] / merged['AJUSTE / PRIMA REF._pos2'] - 1) * 100).round(3)\n",
    "\n",
    "                for index, row in merged.iterrows():\n",
    "                    resultados.append({\n",
    "                        'FECHA': row['FECHA'].strftime('%Y-%m-%d'),  # Usamos la fecha generada\n",
    "                        'PRODUCTO_1': p1,\n",
    "                        'TIPO_CONTRATO_1': t1,\n",
    "                        'PRODUCTO_2': p2,\n",
    "                        'TIPO_CONTRATO_2': t2,\n",
    "                        'AJUSTE_POS1': row['AJUSTE / PRIMA REF._pos1'],\n",
    "                        'AJUSTE_POS2': row['AJUSTE / PRIMA REF._pos2'],\n",
    "                        'SPREAD': row['SPREAD'],\n",
    "                        'RELACION%': row['RELACION%']\n",
    "                    })\n",
    "\n",
    "            # Guardar los resultados en un nuevo archivo CSV local\n",
    "            resultados_df = pd.DataFrame(resultados)\n",
    "            resultados_df.to_csv('relaciones_hoy.csv', index=False)\n",
    "\n",
    "            filas_spread_comparison = len(resultados_df)\n",
    "            return f\"Proceso completado. Se guardaron {filas_spread_comparison} filas en 'relaciones_hoy.csv'.\"\n",
    "\n",
    "        except json.JSONDecodeError:\n",
    "            return \"Error al decodificar la respuesta de la API.\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error durante el procesamiento: {str(e)}\"\n",
    "\n",
    "# Ejecutar la función\n",
    "resultado = procesar_spread_localmente()\n",
    "print(resultado)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
